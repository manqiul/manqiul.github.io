<!DOCTYPE html>
<html lang="en">

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Manqiu  L.


  | Word Representation Methods using Deep Learning

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåå</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="https://manqiul.github.io/blog/2021/representation/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://manqiul.github.io/">
       <span class="font-weight-bold">Manqiu</span>   L.
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              Blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/courses/">
                Courses
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/experiences/">
                Experiences
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item dropdown ">
              <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                Interests
                
              </a>
              <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
              
              
                <a class="dropdown-item" href="/photography/">Photography</a>
              
              
              
                <div class="dropdown-divider"></div>
              
              
              
                <a class="dropdown-item" href="/reading/">Reading</a>
              
              
              </div>
          </li>
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      





<div class="post">

  <header class="post-header">
    <h2 class="post-title">Word Representation Methods using Deep Learning</h2>
    <p class="post-meta">December 13, 2021</p>
    <p class="post-tags">
      <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a>
      
      ¬† ¬∑ ¬†
        
        <a href="/blog/tag/nlp">
          <i class="fas fa-hashtag fa-sm"></i> nlp</a> ¬†
          
      

      
      ¬† ¬∑ ¬†
        
        <a href="/blog/category/paperreading">
          <i class="fas fa-tag fa-sm"></i> paperreading</a> ¬†
          
      

    </p>
  </header>

  <article class="post-content">
    <h2 id="distributed-representations-1-word-embedding">Distributed representations 1: Word embedding</h2>

<h3 id="distributed-representations-of-words-and-phrases-and-their-compositionality">Distributed Representations of Words and Phrases and their Compositionality</h3>

<p>Before we advance to distributed representations of words, we first need to understand the ‚Äúsparse representations‚Äù</p>

<h4 id="understanding-sparse-representations">Understanding Sparse Representations</h4>

<p>Examples:</p>

<ol>
  <li>One-hot encoding</li>
  <li>Bag of words: without order information; representation: a length N vector, N is size of vocabulary. Can be represented as Binary Matrix, Count Matrix or TF-IDF Matrix. Can from bag of words to bag of grams.</li>
</ol>

<figure>

  <picture>
    
      <source media="(max-width: 480px)" srcset="/assets/img/tfidf-480.webp"></source>
    
      <source media="(max-width: 800px)" srcset="/assets/img/tfidf-800.webp"></source>
    
      <source media="(max-width: 1400px)" srcset="/assets/img/tfidf-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/tfidf.png">

  </picture>

  

</figure>

<p>Drawbacks:</p>

<ol>
  <li>not captureing sematic correlations</li>
  <li>vectors are sprse and high-dimensional</li>
</ol>

<p>Source: DLT lecture notes by Chao Zhang, Georgia Tech</p>

<h4 id="understanding-dimension-reduction-and-topic-modeling">Understanding Dimension Reduction and Topic Modeling</h4>

<ul>
  <li>Latent Semantic Analysis
    <ul>
      <li>Using SVD, mapping data into low-dimensional representation by only selecting top k topics</li>
      <li>Source: <a href="https://www.youtube.com/playlist?list=PLroeQp1c-t3qwyrsq66tBxfR6iX6kSslt" target="_blank" rel="noopener noreferrer">LSA Youtube</a>
</li>
    </ul>
  </li>
</ul>

<h4 id="understanding-word-embedding">Understanding word embedding</h4>

<ul>
  <li>word2vec[co-occurrence statistics], Local context window methods
    <ul>
      <li>CBoW: use a window to predict center word</li>
      <li>SkipGarm: use center word to predict surrounding words
        <ul>
          <li>Two layer NN,two weight matrix. each time we will pass one center word, and each word need to be forward pass for k times.</li>
          <li>the hidden layer doesn‚Äôt use any activation function, which is directly passed to the output layer. The output layer using softmax probablility, get the word with the highest prob and compare to the output word‚Äôs on-hot encoding.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Objective: find word representations that are useful for predicting the surrounding words.</li>
</ul>

<figure>

  <picture>
    
      <source media="(max-width: 480px)" srcset="/assets/img/wordembe-480.webp"></source>
    
      <source media="(max-width: 800px)" srcset="/assets/img/wordembe-800.webp"></source>
    
      <source media="(max-width: 1400px)" srcset="/assets/img/wordembe-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/wordembe.png">

  </picture>

  

</figure>

<p>source: <a href="https://towardsdatascience.com/skip-gram-nlp-context-words-prediction-algorithm-5bbf34f84e0c" target="_blank" rel="noopener noreferrer">skip-gram</a>, <a href="https://www.youtube.com/watch?v=pOqz6KuvLV8" target="_blank" rel="noopener noreferrer">skip-gram youtube</a>, <a href="https://arxiv.org/pdf/1301.3781.pdf" target="_blank" rel="noopener noreferrer">paper link</a></p>

<h4 id="about-this-paper">About this Paper</h4>

<p>This paper mainly discussed the extensions of Skip-gram model. First is to use hierarchical softmax to reduce computational complexity. Second is to use negative sampling to reduce noise. Third is to subsampling the frequent word like ‚Äúa‚Äù, ‚Äúthe‚Äù.</p>

<p>source: <a href="https://jonathan-hui.medium.com/nlp-word-embedding-glove-5e7f523999f6" target="_blank" rel="noopener noreferrer">word embedding glove</a></p>

<h3 id="glove-global-vectors-for-word-representation">GloVe: Global Vectors for Word Representation</h3>

<p>First this paper discussed the drawbacks of LSA and local context window methods:</p>

<ul>
  <li>LSA: poorly on the word analogy task</li>
  <li>Local context window: poorly utilize statistics of corpus(such as global co-occurrence counts)</li>
  <li>And then it introduces the GloVe:</li>
</ul>

<figure>

  <picture>
    
      <source media="(max-width: 480px)" srcset="/assets/img/glove-480.webp"></source>
    
      <source media="(max-width: 800px)" srcset="/assets/img/glove-800.webp"></source>
    
      <source media="(max-width: 1400px)" srcset="/assets/img/glove-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/glove.png">

  </picture>

  

</figure>

<p>source: <a href="https://www.youtube.com/watch?v=QoUYlxl1RGI" target="_blank" rel="noopener noreferrer">glove youtube</a>, <a href="https://jonathan-hui.medium.com/nlp-word-embedding-glove-5e7f523999f6" target="_blank" rel="noopener noreferrer">glove medium</a>, <a href="https://blog.csdn.net/coderTC/article/details/73864097" target="_blank" rel="noopener noreferrer">glove csdn</a></p>

<h2 id="distributed-representation-2-deep-contextual-representation">Distributed Representation 2: Deep Contextual Representation</h2>

<h3 id="deep-contextualized-word-representations-elmo">Deep contextualized word representations (ELMo)</h3>

<p><a href="https://www.analyticsvidhya.com/blog/2019/03/learn-to-use-elmo-to-extract-features-from-text/" target="_blank" rel="noopener noreferrer">ELMo</a></p>

<p><a href="https://www.youtube.com/watch?v=YZerhaFMPTw&amp;t=366s" target="_blank" rel="noopener noreferrer">ELMo youtube</a></p>

<figure>

  <picture>
    
      <source media="(max-width: 480px)" srcset="/assets/img/elmo-480.webp"></source>
    
      <source media="(max-width: 800px)" srcset="/assets/img/elmo-800.webp"></source>
    
      <source media="(max-width: 1400px)" srcset="/assets/img/elmo-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/elmo.png">

  </picture>

  

</figure>

<h3 id="bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</h3>

<p><a href="https://www.youtube.com/watch?v=xI0HHN5XKDo" target="_blank" rel="noopener noreferrer">BERT youtube</a></p>

<figure>

  <picture>
    
      <source media="(max-width: 480px)" srcset="/assets/img/BERT1-480.webp"></source>
    
      <source media="(max-width: 800px)" srcset="/assets/img/BERT1-800.webp"></source>
    
      <source media="(max-width: 1400px)" srcset="/assets/img/BERT1-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/BERT1.png">

  </picture>

  

</figure>

<figure>

  <picture>
    
      <source media="(max-width: 480px)" srcset="/assets/img/BERT2-480.webp"></source>
    
      <source media="(max-width: 800px)" srcset="/assets/img/BERT2-800.webp"></source>
    
      <source media="(max-width: 1400px)" srcset="/assets/img/BERT2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/BERT2.png">

  </picture>

  

</figure>

<figure>

  <picture>
    
      <source media="(max-width: 480px)" srcset="/assets/img/BERT3-480.webp"></source>
    
      <source media="(max-width: 800px)" srcset="/assets/img/BERT3-800.webp"></source>
    
      <source media="(max-width: 1400px)" srcset="/assets/img/BERT3-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/BERT3.png">

  </picture>

  

</figure>

<figure>

  <picture>
    
      <source media="(max-width: 480px)" srcset="/assets/img/BERT4-480.webp"></source>
    
      <source media="(max-width: 800px)" srcset="/assets/img/BERT4-800.webp"></source>
    
      <source media="(max-width: 1400px)" srcset="/assets/img/BERT4-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/BERT4.png">

  </picture>

  

</figure>

<figure>

  <picture>
    
      <source media="(max-width: 480px)" srcset="/assets/img/BERT5-480.webp"></source>
    
      <source media="(max-width: 800px)" srcset="/assets/img/BERT5-800.webp"></source>
    
      <source media="(max-width: 1400px)" srcset="/assets/img/BERT5-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/BERT5.png">

  </picture>

  

</figure>

<figure>

  <picture>
    
      <source media="(max-width: 480px)" srcset="/assets/img/BERT6-480.webp"></source>
    
      <source media="(max-width: 800px)" srcset="/assets/img/BERT6-800.webp"></source>
    
      <source media="(max-width: 1400px)" srcset="/assets/img/BERT6-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/BERT6.png">

  </picture>

  

</figure>

<figure>

  <picture>
    
      <source media="(max-width: 480px)" srcset="/assets/img/BERT7-480.webp"></source>
    
      <source media="(max-width: 800px)" srcset="/assets/img/BERT7-800.webp"></source>
    
      <source media="(max-width: 1400px)" srcset="/assets/img/BERT7-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/BERT7.png">

  </picture>

  

</figure>


  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    ¬© Copyright 2022 Manqiu  L..
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>.

    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
